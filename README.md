# CellMechAI  
_A multimodal deep learning framework for predicting cell mechanics from genomics and imaging data_

## üìå Summary
CellMechAI is a proof-of-concept project that integrates **genomics (gene expression)** and **cell imaging** with **deep learning** to predict the **mechanical properties of cells** (e.g., stiffness, deformability).  
This project sits at the intersection of **biology, physics, and artificial intelligence**:  

- **Biology** ‚Üí provides gene expression and microscopy data.  
- **Physics** ‚Üí defines measurable mechanical phenotypes (softness, stiffness, traction).  
- **AI** ‚Üí learns predictive models from multi-modal data.  

Potential applications include:  
- **Classification**: normal vs cancerous cells.  
- **Drug screening**: monitoring how treatments alter cell mechanics.  
- **Biological discovery**: identifying genes most correlated with mechanical states.  

## üó∫Ô∏è Project Plan

**Week 1 (Prototype)**  
- ‚úÖ Load datasets (gene expression + cell images).  
- ‚úÖ Train baseline models (MLP for gene expression, CNN for images).  
- ‚úÖ Build simple multimodal fusion model (concat embeddings).  
- ‚úÖ Add proxy regression head for "mechanical property".  
- ‚úÖ Perform basic interpretability (SHAP on gene encoder).  

**Future Extensions**  
- Add real physics-informed losses (traction balance, smoothness).  
- Use scRNA-seq embeddings (scVI, transformers).  
- Incorporate U-Net for pixel-wise mechanics prediction.  
- Apply explainability techniques to discover gene‚Äìmechanics links.  

## üß† Model Architecture

- **Gene encoder** ‚Üí PCA + MLP ‚Üí latent vector z_rna.  
- **Image encoder** ‚Üí pretrained ResNet18 ‚Üí latent vector z_img.  
- **Fusion** ‚Üí concatenate z_rna + z_img ‚Üí joint embedding z_joint.  
- **Multi-head outputs**:  
  - Head A: Physics regression (proxy stiffness values).  
  - Head B: Classification (normal vs cancer).  
  - Head C: Gene importance analysis.  

